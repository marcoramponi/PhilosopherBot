{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTdSB_pK6Bsh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ALL IMPORTS\n",
    "\n",
    "# -----------------------------------\n",
    "# SpaCy IMPORTS\n",
    "!pip install -U spacy\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "!python -m spacy download en_core_web_lg\n",
    "\n",
    "# Check how many stopwords\n",
    "#len(STOP_WORDS)\n",
    "\n",
    "# Create a spaCy nlp object\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Check if a word is a stopword:\n",
    "#nlp.vocab['thy'].is_stop\n",
    "\n",
    "# Add custom stopwords\n",
    "new_stop_words = ['thy', 'ye', 'thee', 'thou', 'll', 've']\n",
    "for w in new_stop_words :\n",
    "  STOP_WORDS.add(w)\n",
    "\n",
    "# -----------------------------------\n",
    "# TRANSFORMERS IMPORTS\n",
    "#!pip install transformers datasets\n",
    "!pip install --no-cache-dir transformers datasets sentencepiece\n",
    "\n",
    "from transformers import (pipeline, \n",
    "                          AutoModel, \n",
    "                          AutoTokenizer, \n",
    "                          AutoModelForSeq2SeqLM, \n",
    "                          AutoModelForCausalLM, \n",
    "                          DataCollatorForLanguageModeling, \n",
    "                          TrainingArguments, \n",
    "                          Trainer,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yAZcS0hTBDQ"
   },
   "source": [
    "# Topic Extractor + Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT3wxtrZOsBj"
   },
   "source": [
    "## Load data / text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTQzQP88TF3F"
   },
   "outputs": [],
   "source": [
    "# Load list of paragraphs\n",
    "def txt2paragraph(filepath):\n",
    "    with open(filepath) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    paragraph = ''\n",
    "    for line in lines:\n",
    "        if line.isspace():  # is it an empty line?\n",
    "            if paragraph:\n",
    "                yield paragraph\n",
    "                paragraph = ''\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            paragraph += ' ' + line.strip()\n",
    "    yield paragraph\n",
    "\n",
    "# Build the list of raw paragraphs\n",
    "raw_paragraphs = []\n",
    "for par in txt2paragraph('nietzsche.txt'):\n",
    "  par = par.strip()\n",
    "  raw_paragraphs.append(par)\n",
    "\n",
    "# Basic preprocessing\n",
    "import re\n",
    "def paragraphPreprocess(raw_paragraphs: list):\n",
    "  paragraphs = []\n",
    "  prev = ''\n",
    "  for par in raw_paragraphs:\n",
    "    # First we exclude short paragraphs and Footnotes\n",
    "    if (len(par) < 200 and not prev) or \"Footnote\" in par or 'NOTE' in par or 'Nietzsche' in par: \n",
    "      continue \n",
    "    # Next remove non-alpha characters at the beginning of each paragraph\n",
    "    else:\n",
    "      for c in par:\n",
    "        if c.isalpha():\n",
    "          i = par.find(c)\n",
    "          par = par[i:]\n",
    "          break\n",
    "      par = re.sub('[—]', ' ', par)\n",
    "      par = par.replace('-', ' ')\n",
    "      par = par.replace('”', '')\n",
    "      par = par.replace(\"’\", '')\n",
    "      # Remove text between square brackets: \n",
    "      # \"[\\(\\[].*?[\\)\\]]\"  is a REGEX for finding\n",
    "      # the pattern for brackets containing some content\n",
    "      par = re.sub(\"[\\(\\[].*?[\\)\\]]\",\"\", par)\n",
    "      par = re.sub('[_\\'{}()…=\"]', '', par)\n",
    "      par = prev + ' ' + par\n",
    "      par = par.strip()\n",
    "      if par[-1] in [':', ';', ','] or par[-1].isalpha():\n",
    "        prev = par\n",
    "        continue\n",
    "      else:\n",
    "        paragraphs.append(par)\n",
    "        prev = ''\n",
    "  return paragraphs\n",
    "\n",
    "paragraphs = paragraphPreprocess(raw_paragraphs)\n",
    "\n",
    "# Create a Pandas DataFrame out of our list of paragraphs\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(paragraphs, columns =['paragraph'])\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "### Tokenization and further preprocessing with SpaCy\n",
    "\n",
    "# Split text into a list of SENTENCES with SpaCy\n",
    "def split_in_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    return [str(sent).strip() for sent in doc.sents]\n",
    "\n",
    "# Further preprocessing with SpaCy\n",
    "import string\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets, \n",
    "    remove punctuation and remove words containing numbers.\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "df_clean = pd.DataFrame(df.paragraph.apply(lambda x: clean_text(x)))\n",
    "\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "    \n",
    "df[\"paragraph_lemmatize\"] =  df_clean.apply(lambda x: lemmatizer(x['paragraph']), axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTVtWu1VPKIu"
   },
   "source": [
    "## Topic extraction: Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flYmgQjtQK-6",
    "outputId": "131924d6-2921-44fb-ed0a-6a8c2672208d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:294: FutureWarning:\n",
      "\n",
      "The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning:\n",
      "\n",
      "Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP WORDS FOR TOPIC #0\n",
      "['pain', 'high', 'animal', 'feel', 'cause', 'woman', 'time', 'long', 'power', 'nature', 'self', 'soul', 'strong', 'bad', 'thing', 'know', 'virtue', 'great', 'good', 'man']\n",
      "\n",
      "\n",
      "THE TOP WORDS FOR TOPIC #1\n",
      "['word', 'silent', 'stand', 'night', 'cry', 'look', 'long', 'laugh', 'day', 'speak', 'mountain', 'cave', 'unto', 'hath', 'like', 'hear', 'heart', 'come', 'spake', 'zarathustra']\n",
      "\n",
      "\n",
      "THE TOP WORDS FOR TOPIC #2\n",
      "['time', 'day', 'artist', 'let', 'richard', 'europe', 'culture', 'goethe', 'spirit', 'like', 'great', 'book', 'art', 'taste', 'people', 'germany', 'musician', 'music', 'wagner', 'german']\n",
      "\n",
      "\n",
      "THE TOP WORDS FOR TOPIC #3\n",
      "['poet', 'appearance', 'hero', 'drama', 'æsthetic', 'artistic', 'picture', 'greek', 'dream', 'nature', 'phenomenon', 'chorus', 'myth', 'tragic', 'world', 'apollonian', 'tragedy', 'music', 'art', 'dionysian']\n",
      "\n",
      "\n",
      "THE TOP WORDS FOR TOPIC #4\n",
      "['faith', 'save', 'jewish', 'hate', 'punishment', 'act', 'child', 'concept', 'evil', 'thing', 'holy', 'shall', 'kingdom', 'man', 'believe', 'priest', 'sin', 'world', 'love', 'god']\n",
      "\n",
      "\n",
      "THE TOP WORDS FOR TOPIC #5\n",
      "['live', 'priest', 'power', 'form', 'way', 'sort', 'self', 'concept', 'thing', 'religion', 'natural', 'faith', 'people', 'state', 'death', 'church', 'instinct', 'christian', 'christianity', 'life']\n",
      "\n",
      "\n",
      "THE TOP WORDS FOR TOPIC #6\n",
      "['declare', 'anti', 'strong', 'new', 'realise', 'world', 'passion', 'reality', 'aim', 'desideratum', 'mean', 'science', 'power', 'kind', 'instinct', 'old', 'self', 'virtue', 'ascetic', 'ideal']\n",
      "\n",
      "\n",
      "THE TOP WORDS FOR TOPIC #7\n",
      "['long', 'purpose', 'science', 'knowledge', 'power', 'action', 'philosophy', 'high', 'mean', 'regard', 'instinct', 'valuation', 'nihilism', 'question', 'world', 'philosopher', 'truth', 'moral', 'morality', 'value']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topic\n",
       "0    648\n",
       "1    313\n",
       "2    199\n",
       "3    230\n",
       "4    195\n",
       "5    353\n",
       "6    110\n",
       "7    360\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DOCUMENT TERM MATRIX\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=3, stop_words=STOP_WORDS)\n",
    "\n",
    "dtm = tfidf.fit_transform(df['paragraph_lemmatize'])\n",
    "\n",
    "# Create an instance of NMF with n_comp components\n",
    "from sklearn.decomposition import NMF\n",
    "n_comp = 8\n",
    "nmf_model = NMF(n_components=n_comp,random_state=42)\n",
    "nmf_model.fit(dtm)\n",
    "\n",
    "# Print the most common words for each topic\n",
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names_out()[i] for i in topic.argsort()[-20:]])\n",
    "    print('\\n')\n",
    "   \n",
    "# ASSIGN Topic to paragraphs and COUNT paragraphs/topic\n",
    "\n",
    "topic_results = nmf_model.transform(dtm)\n",
    "df['topic'] = topic_results.argmax(axis=1)\n",
    "\n",
    "df.groupby(['topic']).size()\n",
    "\n",
    "#df.head(10)\n",
    "#df[df['topic'] == topic].head() # Filter df by topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgb1ppKwtaFH"
   },
   "source": [
    "## Text to Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vs3VnMaVgB1Q"
   },
   "outputs": [],
   "source": [
    "def textToParagraph(text):\n",
    "  \"\"\"\n",
    "  Input: text - a string of text\n",
    "  Output: Full Paragraph from the DataFrame that best matches with input text\n",
    "\n",
    "  Description: \n",
    "  text -> predict Topic -> compute similarity ONLY with paragraphs in this Topic\n",
    "       -> return paragraph with highest similarity score\n",
    "  \"\"\"\n",
    "\n",
    "  # PREDICT Topic\n",
    "  text = lemmatizer(clean_text(text))\n",
    "  X = tfidf.transform([text]) # transform the TF-IDF\n",
    "  nmf_features = nmf_model.transform(X) # get the nmf_features (score) vector\n",
    "  topic = nmf_features.argmax()\n",
    "\n",
    "  # Compute SIMILARITY with paragraphs in this Topic\n",
    "\n",
    "  # Similarity function: (text, paragraph)\n",
    "  def sim(text, par):\n",
    "    # Clean text, remove stopwords and tokenize\n",
    "    doc = nlp(lemmatizer(clean_text(par)))\n",
    "    return nlp(text).similarity(doc)\n",
    "\n",
    "  # Get series of similarity scores on the DataFrame sliced by topic\n",
    "  scores = df[df['topic'] == topic].apply(lambda x: sim(text, x['paragraph']), axis=1)\n",
    "\n",
    "  # Return most similar paragraph\n",
    "  id = scores.idxmax() # Get id of the max score\n",
    "  return df['paragraph'][id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5zw2m8NuzFg"
   },
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyJu6RtsCDbZ"
   },
   "outputs": [],
   "source": [
    "# Load summarization pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_1_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(model_1_name)\n",
    "model_1 = AutoModelForSeq2SeqLM.from_pretrained(model_1_name)\n",
    "  \n",
    "summarizer = pipeline(\"summarization\", model=model_1_name, tokenizer=tokenizer_1)\n",
    "\n",
    "# TRUNCATE string to TWO SENTENCES\n",
    "def firstTwoSentences(s: str):\n",
    "  \"\"\"\n",
    "  Input: string s\n",
    "  Returns: first two sentences in s\n",
    "  \"\"\"\n",
    "  # Truncate string at the last '.' or '?' or '!'\n",
    "  reverse = s[::-1]\n",
    "  LastFullStop = reverse.find(\".\")\n",
    "  LastQmark = reverse.find(\"?\")\n",
    "  LastXmark = reverse.find(\"!\")\n",
    "  lastStopSymbol = max(LastFullStop, LastQmark, LastXmark)\n",
    "\n",
    "  if lastStopSymbol >= 0 :\n",
    "    s = s[: len(s) - lastStopSymbol]\n",
    "\n",
    "  # Return the first two sentences\n",
    "  return ' '.join(split_in_sentences(s)[:2])\n",
    "\n",
    "# SUMMARY snippet\n",
    "def summary(paragraph: str):\n",
    "  \"\"\"\n",
    "  Input: paragraph - a string\n",
    "  Output: summary - a string. The summary of the paragraph.\n",
    "  Parameters: we set min_length to 10% of the paragraph's length and max_length to 40% respectively\n",
    "  \"\"\"\n",
    "  min_length=len(tokenizer_1(paragraph)['input_ids']) // 10\n",
    "  max_length= 5*min_length\n",
    "  summary = summarizer(paragraph, min_length=min_length, max_length=max_length)[0]['summary_text']\n",
    "  return firstTwoSentences(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEhuOlJWMtup",
    "outputId": "7f0732c6-a27d-403b-87b8-10bc69092d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAGRAPH:\n",
      "Our deepest insights must  and should  appear as follies, and under certain circumstances as crimes, when they come unauthorizedly to the ears of those who are not disposed and predestined for them.\n",
      "The exoteric and the esoteric, as they were formerly distinguished by philosophers  among the Indians, as among the Greeks, Persians, and Mussulmans, in short, wherever people believed in gradations of rank and NOT in equality and equal rights  are not so much in contradistinction to one another in respect to the exoteric class, standing without, and viewing, estimating, measuring, and judging from the outside, and not from the inside; the more essential distinction is that the class in question views things from below upwards  while the esoteric class views things FROM ABOVE DOWNWARDS.\n",
      "There are heights of the soul from which tragedy itself no longer appears to operate tragically; and if all the woe in the world were taken together, who would dare to decide whether the sight of it would NECESSARILY seduce and constrain to sympathy, and thus to a doubling of the woe?...\n",
      "That which serves the higher class of men for nourishment or refreshment, must be almost poison to an entirely different and lower order of human beings.\n",
      "The virtues of the common man would perhaps mean vice and weakness in a philosopher; it might be possible for a highly developed man, supposing him to degenerate and go to ruin, to acquire qualities thereby alone, for the sake of which he would have to be honoured as a saint in the lower world into which he had sunk.\n",
      "There are books which have an inverse value for the soul and the health according as the inferior soul and the lower vitality, or the higher and more powerful, make use of them.\n",
      "In the former case they are dangerous, disturbing, unsettling books, in the latter case they are herald calls which summon the bravest to THEIR bravery.\n",
      "Books for the general reader are always ill smelling books, the odour of paltry people clings to them.\n",
      "Where the populace eat and drink, and even where they reverence, it is accustomed to stink.\n",
      "One should not go into churches if one wishes to breathe PURE air.\n",
      "\n",
      "SUMMARY:\n",
      "Exoteric and the esoteric were formerly distinguished by philosophers among the Indians, Greeks, Persians, and Mussulmans.\n",
      "There are heights of the soul from which tragedy itself no longer appears to operate tragically.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PARAGRAPH:\n",
      "Do not let us forget that, when Hegel and Schelling were misleading the minds of Germany, Wagner was still young: that he guessed, or rather fully grasped, that the only thing which Germans take seriously is “the idea, that is to say, something obscure, uncertain, wonderful; that among Germans lucidity is an objection, logic a refutation.\n",
      "Schopenhauer rigorously pointed out the dishonesty of Hegels and Schellings age, rigorously, but also unjustly, for he himself, the pessimistic old counterfeiter, was in no way more “honest than his more famous contemporaries.\n",
      "But let us leave morality out of the question, Hegel is a matter of taste.\n",
      "And not only of German but of European taste!\n",
      "A taste which Wagner understood!\n",
      "which he felt equal to!\n",
      "which he has immortalised!\n",
      "All he did was to apply it to music he invented a style for himself, which might mean an “infinity of things, he was Hegels heir.\n",
      "Music as “Idea.\n",
      "\n",
      "SUMMARY:\n",
      "Wagner understood that the only thing which Germans take seriously is “the idea’.\n",
      "Schopenhauer rigorously pointed out the dishonesty of Hegels and Schellings age.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PARAGRAPH:\n",
      "The life of the Saviour was simply a carrying out of this way of life  and so was his death....\n",
      "He no longer needed any formula or ritual in his relations with God  not even prayer.\n",
      "He had rejected the whole of the Jewish doctrine of repentance and atonement; he knew that it was only by a way of life that one could feel ones self divine, blessed, evangelical, a child of God.\n",
      "Not by repentance, not by prayer and forgiveness is the way to God: only the Gospel way leads to God  it is itself God!\n",
      "What the Gospels abolished was the Judaism in the concepts of sin, forgiveness of sin, faith, salvation through faith  the whole ecclesiastical dogma of the Jews was denied by the glad tidings.\n",
      "\n",
      "SUMMARY:\n",
      "The Saviour rejected the whole of the Jewish doctrine of repentance and atonement.\n",
      "Not by repentance, not by prayer and forgiveness is the way to God: only the Gospel way leads to God.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print text by sentences\n",
    "def printBySentence(text: str):\n",
    "  for sent in split_in_sentences(text):\n",
    "    print(sent)\n",
    "  return\n",
    "\n",
    "# TEST SUMMARIZER with a few paragraphs\n",
    "import random\n",
    "for step in range(3):\n",
    "  t = random.randint(0, len(df['paragraph']))\n",
    "  paragraph = df['paragraph'][t]\n",
    "  print(\"PARAGRAPH:\")\n",
    "  printBySentence(paragraph)\n",
    "\n",
    "  print(\"\\nSUMMARY:\")\n",
    "  printBySentence(summary(paragraph))\n",
    "  print(100*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nU2IJ5OyQUc6"
   },
   "source": [
    "# Text to (relevant) paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEs5pUeKJd3w",
    "outputId": "54d3f425-feb6-4d3f-fea2-aaff4ed8621f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Input:  How much power should people have in european politics? \n",
      "\n",
      "Can a crasser, more indolent, and more lounging form of Christian belief be imagined, than that of the average German Protestant?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input:  Can religion save the evil in the world? \n",
      "\n",
      "The Christian concept of a god is one of the most corrupt concepts that has ever been set up in the world.\n",
      "God degenerated into the contradiction of life.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input:  What is the meaning of Love, to live in a more peaceful world? \n",
      "\n",
      "What concerns me is the psychological type of the Saviour.\n",
      "This type might be depicted in the Gospels, in however mutilated a form and however much overladen with extraneous characters.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input:  Is Nihilism an alternative to hope? \n",
      "\n",
      "Pessimism is not a problem but a symptom,  that the term ought to be replaced by Nihilism.\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "testQuestion = []\n",
    "testQuestion.append('How much power should people have in european politics?')\n",
    "testQuestion.append('Can religion save the evil in the world?')\n",
    "testQuestion.append('What is the meaning of Love, to live in a more peaceful world?')\n",
    "testQuestion.append('Is Nihilism an alternative to hope?')\n",
    "\n",
    "for text in testQuestion:\n",
    "  print(100*'-')\n",
    "  print(\"Input: \", text, '\\n') \n",
    "  paragraph = textToParagraph(text)\n",
    "  printBySentence(summary(paragraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1GCGMixysRm"
   },
   "source": [
    "# Question Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0Ra_ZH8-49L"
   },
   "outputs": [],
   "source": [
    "# Load the TOKENIZER\n",
    "model_name = \"distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer_2.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKcVkeOOVNtz",
    "outputId": "2439a5bf-20de-43a4-ca9f-3ffb3da4e4df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GENERATE QUESTION WITH FINE-TUNED MODEL\n",
    "\n",
    "# Load the fine-tuned model from local (a file pytorch_model.bin must be in the current directory)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./\")\n",
    "\n",
    "# Snippet to TRUNCATE strings to QUESTION mark\n",
    "def questionTruncate(s: str):\n",
    "  \"\"\"\n",
    "  String polisher for outputting clean questions.\n",
    "  Input: string s\n",
    "  Returns: string s truncated at the FIRST \"?\" char or at the LAST \".\" char\n",
    "  \"\"\"\n",
    "  reverse = s[::-1]\n",
    "  LastFullStop = reverse.find(\".\")\n",
    "  FirstQuestMark = s.find(\"?\")\n",
    "  if FirstQuestMark >= 0 :\n",
    "    return s[: FirstQuestMark +1 ]\n",
    "  elif LastFullStop >= 0 :\n",
    "    return s[: len(s) - LastFullStop]\n",
    "  return s\n",
    "\n",
    "# Test\n",
    "#for s in ['Multiple? more than one?', 'First? Then no question.', 'No punctuation', 'No question.']:\n",
    "#  print(questionTruncate(s))\n",
    "\n",
    "\n",
    "# QUESTION GENERATOR\n",
    "\n",
    "def questionGenerator(text: str):\n",
    "  \"\"\"\n",
    "  Input:\n",
    "  Returns:\n",
    "  \"\"\"\n",
    "  # ENCODE input and add 'end-of-string' token\n",
    "  input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors=\"pt\")\n",
    "  l = len(input_ids)\n",
    "  # GENERATE\n",
    "  chat_history_ids = model.generate(\n",
    "      input_ids,\n",
    "      max_length=l+80,\n",
    "      do_sample=True,\n",
    "      top_p=0.91,\n",
    "      top_k=10,\n",
    "      temperature=0.75,\n",
    "      early_stopping=True, #####\n",
    "      pad_token_id=tokenizer.eos_token_id\n",
    "  )\n",
    "\n",
    "  # DECODE to string\n",
    "  output = tokenizer.decode(chat_history_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1mEjqoZHlP-",
    "outputId": "2f0c3a40-6bb3-4fab-84ac-2c77be55fa05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: What does Nihilism mean? \n",
      "\n",
      "Bot: The world of the modern man is not always a good thing. What is the meaning of the word?--The term is a term which means the word itself. To put it simply, there is no better word than a German word for a German word for a German word. What is the meaning of a German word for the German word for the German word for \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Text: What is Pessimism \n",
      "\n",
      "Bot: What is the meaning of the word pessimism?In the present day, it is the concept of the word pessimism.The term pessimism is the expression of a desire to attain to an ideal.In order to understand why, why?Because pessimism is an expression of a desire to attain to an ideal, it is a necessary means of overcoming the prejudices of the \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Text: What is the purpose? \n",
      "\n",
      "Bot: This is what is called the meaning of the word, and I have a good reason to ask: what is it that means to the philosopher?A. The term meaning is the word meaning, the word meaning to be understood as a meaning of life, or as a meaning of the future.What is the meaning of the word?A. The meaning of life is the \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Text: Prejudice against science? \n",
      "\n",
      "Bot: What is the meaning of the word science?To be sure, I have never been to the point of view of the philosopher, but what is the meaning of the word science?The term science is the means of the word for the purpose of being to understand the natural sciences, and the meaning of a certain type of philosophy.The term science is the word for a \n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "for text in ['What does Nihilism mean?', 'What is Pessimism', 'What is the purpose?', 'Prejudice against science?']:\n",
    "  print(f\"Text: {text} \\n\\nBot: {questionGenerator(text)} \\n\", 100*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCwF0uEv7Kp4"
   },
   "source": [
    "# PhilosopherBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hOg7ufTd7OoM"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN LOGIC IS AS FOLLOWS:\n",
    "input -> topic -> relevant paragraph \n",
    "-> use last sentence of paragraph to generate question \n",
    "-> print(question, paragraph, summarization of previous two)\n",
    "\"\"\"\n",
    "\n",
    "def bot(text):\n",
    "  paragraph = textToParagraph(text)\n",
    "  summarized_paragraph = summary(paragraph)\n",
    "\n",
    "  print(summarized_paragraph)\n",
    "\n",
    "  lastSentence = split_in_sentences(summarized_paragraph)[-1]\n",
    "  question = questionGenerator(lastSentence)\n",
    "  question = questionTruncate(question)\n",
    "  for sent in split_in_sentences(question):\n",
    "    print(sent)\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKn_jxgsZ9SF"
   },
   "outputs": [],
   "source": [
    "testQuestion = []\n",
    "text = 'Tell me about God and the meaning of Life'\n",
    "for step in range(5):\n",
    "  testQuestion.append(text)\n",
    "  text = questionGenerator(text)\n",
    "\n",
    "for text in testQuestion:\n",
    "  print(\"Input text:\\n\" + text)\n",
    "  print(\"Bot: \\n\")\n",
    "  bot(text)\n",
    "  print(100 * '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZrHW6Ugo3sy",
    "outputId": "f9538132-44c7-4391-ce42-9da70a28bb40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "How much power should people have in european politics?\n",
      "\n",
      "Can a crasser, more indolent, and more lounging form of Christian belief be imagined, than that of the average German Protestant?\n",
      "When you think of it as a matter of fact, this is what it is called, and is a word for it.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Can religion save the evil in the world?\n",
      "\n",
      "The Christian concept of a god is one of the most corrupt concepts that has ever been set up in the world. God degenerated into the contradiction of life.\n",
      "A man is dying for the world to know, but what?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "What is the meaning of Love, to live in a more peaceful world?\n",
      "\n",
      "What concerns me is the psychological type of the Saviour. This type might be depicted in the Gospels, in however mutilated a form and however much overladen with extraneous characters.\n",
      "We know that, as a matter of fact, the term is quite a term for the first time, and this is why we are here at the end of the story.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Is Nihilism an alternative to hope?\n",
      "\n",
      "Pessimism is not a problem but a symptom,  that the term ought to be replaced by Nihilism.\n",
      "The world is changing, and the time is upon us.\n",
      "What is the meaning of it all?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "If children grow up in this World, how can we teach them how to live more sustainably?\n",
      "\n",
      "\"I am no seeker.\n",
      "It is the first time that you have heard the word 'nasty' in your mind, but it is not the first time that I have heard the word 'nasty'.\n",
      "What is it?\n"
     ]
    }
   ],
   "source": [
    "testQuestion = []\n",
    "testQuestion.append('How much power should people have in european politics?')\n",
    "testQuestion.append('Can religion save the evil in the world?')\n",
    "testQuestion.append('What is the meaning of Love, to live in a more peaceful world?')\n",
    "testQuestion.append('Is Nihilism an alternative to hope?')\n",
    "testQuestion.append('If children grow up in this World, how can we teach them how to live more sustainably?')\n",
    "\n",
    "for text in testQuestion:\n",
    "  print(100 * '-')  \n",
    "  print(text + '\\n')\n",
    "  bot(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNyPMzMoP6Op"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GEJ-YxlcPD3I",
    "Ld4PUeYhECyz",
    "7CMGD0oeqH1Z"
   ],
   "name": "PhilosopherBot (final).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
